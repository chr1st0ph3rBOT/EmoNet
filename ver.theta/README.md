# ver.theta 상세 설계

이 문서는 논문 초안 수준의 설명으로, 코드를 직접 보지 않아도 ver.theta의 동작 개념을 이해할 수 있도록 구성한다.

## 개요
ver.theta는 감정 상태 요약 벡터(`NTL`)와 내부 상태(`K`), 그리고 임시 기억 스택(`IPT`)을 통해 학습 신호를 조절하는 신경망 설계를 목표로 한다. 핵심 아이디어는 **상태 요약 → 가중치 변화량(ΔW) 조절**의 흐름을 명확히 정의하는 것이다.

## 핵심 상태 변수
- `NTL=[D,S,NE,M]`: 네트워크 전체 상태를 요약하는 4차원 벡터다. 각 요소는 특정 정서·활성 패턴을 대변하며, 학습 및 가중치 변동의 조절 신호로 사용된다.
- `K`(고정 범위): 입력 뉴런들의 상태와 가중치로부터 계산되는 내부 값이다. 계산 결과가 무제한으로 커지는 것을 방지하기 위해, 지정된 고정 범위로 클리핑된다.
- `IPT`(메모리 스택): 최근 입력/상태를 임시로 저장하는 스택 구조다. 장·단기 기억을 분리하기 위한 기초로 사용되며, 규칙은 실험적으로 조정 가능하다.

## K 업데이트 규칙
1. 입력 뉴런의 K와 해당 가중치의 선형 결합을 계산한다.
2. 계산된 값을 사전에 정의된 고정 범위로 클리핑한다.
3. 클리핑된 결과를 새로운 K로 갱신한다.

이 과정은 K가 입력 변화에 반응하되 폭주하지 않도록 제약한다.

## ΔW 정의
`ΔW`는 연결된 뉴런 수 또는 연결성의 크기에 의해 결정되는 값이다. 즉, 더 큰 연결성은 더 큰 변화량 가능성을 의미한다. 단, 실제 변화량은 `NTL`에 의해 조절된다.

## ΔW 조절 원칙
`NTL`은 `ΔW`의 변화율과 증감 폭을 제어한다. 이는 **감정 상태 요약이 학습 강도를 직접 조절한다**는 설계 결정이다. 따라서 동일한 입력이라도 `NTL`이 다르면 가중치 업데이트의 강도와 방향성이 달라질 수 있다.

## NTL 추출 방식
`NTL`은 기본적으로 LLM을 통해 추출한다. ML 기반 추정은 정확도가 낮은 fallback으로만 사용하며, 시스템의 기본 경로는 LLM 기반 추출에 있다.

## 메모리 규칙
`IPT`는 현재 임시 규칙에 기반해 동작한다. 이는 초기 설계 단계에서의 가변 요소로, 향후 실험 결과에 따라 변경 가능함을 명시한다.
