{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "686bf8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda, dtype: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "# 환경\n",
    "import os, random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "os.environ[\"TORCH_COMPILE_DISABLE\"] = \"1\"  # 토치 컴파일 비활성\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch_dtype = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\"); torch_dtype = torch.float16\n",
    "else:\n",
    "    device = torch.device(\"cpu\"); torch_dtype = torch.float32\n",
    "\n",
    "print(f\"Device: {device}, dtype: {torch_dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f628eb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\gptoss\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "You have loaded an FP4 model on CPU and have a CUDA device available, make sure to set your model on a GPU device in order to run your model. To remove this warning, pass device_map = 'cuda'. \n",
      "Fetching 41 files: 100%|██████████| 41/41 [00:00<?, ?it/s]\n",
      "Fetching 41 files: 100%|██████████| 41/41 [00:00<?, ?it/s]?it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.04s/it]\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model & tokenizer ready.\n"
     ]
    }
   ],
   "source": [
    "# 모델 및 토크나이저 로드\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "MODEL_ID = \"openai/gpt-oss-20b\"\n",
    "REVISION = None\n",
    "\n",
    "_tok = AutoTokenizer.from_pretrained(MODEL_ID, revision=REVISION, trust_remote_code=True, use_fast=True)\n",
    "if _tok.pad_token is None:\n",
    "    _tok.pad_token = _tok.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    revision=REVISION,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    low_cpu_mem_usage=False,\n",
    "    device_map=None,\n",
    ")\n",
    "model.to(device); model.eval()\n",
    "\n",
    "_gen = pipeline(\"text-generation\", model=model, tokenizer=_tok,\n",
    "                device=0 if device.type==\"cuda\" else -1)\n",
    "\n",
    "print(\"Model & tokenizer ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a861966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'analysisThe user says \"안녕! 테스트야.\" which means \"Hi! This is a test.\" They likely want a friendly response. The instruction: \"You are ChatGPT, a'}]\n"
     ]
    }
   ],
   "source": [
    "# LLM 테스트\n",
    "TEST_PROMPT = [{\"role\": \"user\", \"content\": \"안녕! 테스트야.\"}]\n",
    "GEN_KW = dict(max_new_tokens=40, do_sample=False,\n",
    "              eos_token_id=_tok.eos_token_id, pad_token_id=_tok.pad_token_id,\n",
    "              return_full_text=False)\n",
    "\n",
    "out = _gen(TEST_PROMPT, **GEN_KW)\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a361618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# LLM 텍스트 -> 신경전달물질 4축 스코어 추정 (OSS 모델용 견고 파서 포함)\n",
    "\n",
    "import re\n",
    "import json\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "class LLM:\n",
    "    # ====== 설정 ======\n",
    "    CHEATSHEET = \"\"\"\n",
    "Definitions (short):\n",
    "- Dopamine: reward/novelty/goal pursuit; approach & motivation.\n",
    "- Serotonin: calm/satiety/stability; pro-social, contentment.\n",
    "- Norepinephrine: alertness/vigilance/stress mobilization.\n",
    "- Melatonin: circadian sleep drive; drowsiness/night-time cues.\n",
    "\n",
    "Scoring rubric:\n",
    "- Map cues in text to each axis independently in [0,1].\n",
    "- Strong evidence -> ≥0.7, weak/ambiguous -> 0.3~0.6, absent -> ≤0.2.\n",
    "- Do NOT infer medical claims; this is a heuristic proxy from language only.\n",
    "\"\"\".strip()\n",
    "\n",
    "    EXAMPLES: List[Tuple[str, Dict[str, float]]] = [\n",
    "        ('Just aced the exam! Can’t wait to start a new project.',\n",
    "         {\"dopamine\":0.82,\"serotonin\":0.55,\"norepinephrine\":0.38,\"melatonin\":0.10}),\n",
    "        ('Breathing slowed, grateful after dinner with friends.',\n",
    "         {\"dopamine\":0.35,\"serotonin\":0.78,\"norepinephrine\":0.22,\"melatonin\":0.18}),\n",
    "        ('It’s 2am; eyes heavy; will sleep soon.',\n",
    "         {\"dopamine\":0.20,\"serotonin\":0.32,\"norepinephrine\":0.18,\"melatonin\":0.85}),\n",
    "    ]\n",
    "\n",
    "    REQUIRED_KEYS = (\"dopamine\", \"serotonin\", \"norepinephrine\", \"melatonin\")\n",
    "\n",
    "    def __init__(self):\n",
    "        # 출력 마커 + 정확히 4키만\n",
    "        self.EMO_SYSTEM = (\n",
    "            \"You are EmotionScore. Respond with JSON ONLY, wrapped by <json>...</json>.\\n\"\n",
    "            \"Output exactly these four keys as floats in [0,1]: \"\n",
    "            \"dopamine, serotonin, norepinephrine, melatonin.\\n\"\n",
    "            \"No explanation. No extra keys. No text outside JSON.\"\n",
    "        )\n",
    "\n",
    "    # ====== 유틸 ======\n",
    "    @staticmethod\n",
    "    def _clip01(x):\n",
    "        try:\n",
    "            return max(0.0, min(1.0, float(x)))\n",
    "        except:\n",
    "            return 0.0\n",
    "\n",
    "    @staticmethod\n",
    "    def _coerce_float01(v):\n",
    "        \"\"\"문자열/퍼센트/과학표기 등 → [0,1] float 변환\"\"\"\n",
    "        try:\n",
    "            if isinstance(v, (int, float)):\n",
    "                return max(0.0, min(1.0, float(v)))\n",
    "            if isinstance(v, str):\n",
    "                s = v.strip().lower()\n",
    "                if s.endswith(\"%\"):  # '70%' -> 0.7\n",
    "                    num = float(s[:-1].strip())\n",
    "                    return max(0.0, min(1.0, num/100.0))\n",
    "                return max(0.0, min(1.0, float(s)))\n",
    "        except:\n",
    "            pass\n",
    "        return 0.0\n",
    "\n",
    "    @staticmethod\n",
    "    def _strip_code_fences(text: str) -> str:\n",
    "        # ```json ... ``` 제거\n",
    "        if text.startswith(\"```\"):\n",
    "            lines = text.splitlines()\n",
    "            if len(lines) >= 2 and lines[0].startswith(\"```\"):\n",
    "                for i in range(1, len(lines)):\n",
    "                    if lines[i].startswith(\"```\"):\n",
    "                        return \"\\n\".join(lines[1:i])\n",
    "        return text\n",
    "\n",
    "    def _extract_json_text(self, raw: str) -> str | None:\n",
    "        if not raw:\n",
    "            return None\n",
    "        m = re.search(r\"<json>\\s*(\\{.*?\\})\\s*</json>\", raw, re.S | re.I)\n",
    "        if m:\n",
    "            return m.group(1)\n",
    "        cleaned = self._strip_code_fences(raw)\n",
    "        m2 = re.search(r\"\\{.*\\}\", cleaned, re.S)\n",
    "        return m2.group(0) if m2 else None\n",
    "\n",
    "    def _safe_parse(self, json_text: str | None) -> Dict[str, float]:\n",
    "        if not json_text:\n",
    "            return {k: 0.0 for k in self.REQUIRED_KEYS}\n",
    "        try:\n",
    "            data = json.loads(json_text)\n",
    "            if not isinstance(data, dict):\n",
    "                raise ValueError(\"not a dict\")\n",
    "        except:\n",
    "            return {k: 0.0 for k in self.REQUIRED_KEYS}\n",
    "\n",
    "        fixed = {}\n",
    "        for k in self.REQUIRED_KEYS:\n",
    "            fixed[k] = self._coerce_float01(data.get(k, 0.0))\n",
    "        return fixed\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth01(vals: List[float], tau: float = 0.12) -> List[float]:\n",
    "        \"\"\"극단값 완화(선택적)\"\"\"\n",
    "        return [min(1.0, max(0.0, v*(1-tau) + 0.5*tau)) for v in vals]\n",
    "\n",
    "    # ====== 프롬프트 생성 ======\n",
    "    def _build_prompt(self, IPT: str) -> str:\n",
    "        fewshot = \"\\n\".join(\n",
    "            f'Text: \"{t}\"\\n<json>{json.dumps(ex, separators=(\",\",\":\"))}</json>'\n",
    "            for t, ex in self.EXAMPLES\n",
    "        )\n",
    "        return (\n",
    "            f\"{self.EMO_SYSTEM}\\n\"\n",
    "            f\"{self.CHEATSHEET}\\n\"\n",
    "            f\"{fewshot}\\n\"\n",
    "            f'Text: \"{IPT}\"\\n'\n",
    "            f\"JSON:\"\n",
    "        )\n",
    "\n",
    "    # ====== 공개 API ======\n",
    "    def IPT2NTL(self, IPT: str, log_raw: bool = True) -> List[int]:\n",
    "        \"\"\"\n",
    "        입력 텍스트 -> 4축 점수 산출 -> 상위 2개 인덱스 반환 (0:dopamine, 1:serotonin, 2:norepinephrine, 3:melatonin)\n",
    "        외부 의존: _gen(prompt, ...), _tok.eos_token_id / pad_token_id\n",
    "        \"\"\"\n",
    "        prompt = self._build_prompt(IPT)\n",
    "\n",
    "        out = _gen(\n",
    "            prompt,\n",
    "            max_new_tokens=120,\n",
    "            do_sample=False,\n",
    "            return_full_text=False,\n",
    "            eos_token_id=_tok.eos_token_id,\n",
    "            pad_token_id=_tok.pad_token_id\n",
    "        )\n",
    "\n",
    "        raw = (out[0].get(\"generated_text\", \"\") if out and isinstance(out, list) else \"\") or \"\"\n",
    "        if log_raw:\n",
    "            print(\"-----[OSS raw output]-----\")\n",
    "            print(raw)\n",
    "            print(\"-----[/OSS raw output]----\")\n",
    "\n",
    "        json_text = self._extract_json_text(raw)\n",
    "        data = self._safe_parse(json_text)\n",
    "        if log_raw:\n",
    "            print(f\"[LOG][json] {data}\")\n",
    "\n",
    "        vals = [self._clip01(data[k]) for k in self.REQUIRED_KEYS]\n",
    "        vals = self._smooth01(vals, tau=0.12)  # 선택적 스무딩\n",
    "        if log_raw:\n",
    "            print(f\"[LOG][vals] {vals}\")\n",
    "\n",
    "        # 동점 안정 정렬(인덱스 보조키)\n",
    "        NTL = sorted(range(4), key=lambda i: (-vals[i], i))[:2]\n",
    "        return NTL\n",
    "\n",
    "    def IPT2SCORES(self, IPT: str, log_raw: bool = False) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        점수 딕셔너리 그대로 반환이 필요할 때 사용.\n",
    "        \"\"\"\n",
    "        prompt = self._build_prompt(IPT)\n",
    "        out = _gen(\n",
    "            prompt,\n",
    "            max_new_tokens=120,\n",
    "            do_sample=False,\n",
    "            return_full_text=False,\n",
    "            eos_token_id=_tok.eos_token_id,\n",
    "            pad_token_id=_tok.pad_token_id\n",
    "        )\n",
    "        raw = (out[0].get(\"generated_text\", \"\") if out and isinstance(out, list) else \"\") or \"\"\n",
    "        if log_raw:\n",
    "            print(\"-----[OSS raw output]-----\")\n",
    "            print(raw)\n",
    "            print(\"-----[/OSS raw output]----\")\n",
    "\n",
    "        json_text = self._extract_json_text(raw)\n",
    "        data = self._safe_parse(json_text)\n",
    "        vals = [self._clip01(data[k]) for k in self.REQUIRED_KEYS]\n",
    "        vals = self._smooth01(vals, tau=0.12)\n",
    "        return {k: vals[i] for i, k in enumerate(self.REQUIRED_KEYS)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a8b05c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LLM' object has no attribute 'EXAMPLES'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# LLM test\u001b[39;00m\n\u001b[32m      2\u001b[39m _llm = LLM()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m ntl, why = \u001b[43m_llm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mIPT2NTL\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m행복해\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_raw\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 96\u001b[39m, in \u001b[36mLLM.IPT2NTL\u001b[39m\u001b[34m(self, IPT, log_raw)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mIPT2NTL\u001b[39m(\u001b[38;5;28mself\u001b[39m, IPT: \u001b[38;5;28mstr\u001b[39m, log_raw: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m) -> Tuple[List[\u001b[38;5;28mint\u001b[39m], \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m     87\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[33;03m    입력 텍스트 -> LLM 점수 산출 -> 상위 2개 축 인덱스와 근거 문자열을 함께 반환.\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[33;03m    인덱스: 0:dopamine, 1:serotonin, 2:norepinephrine, 3:melatonin\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     94\u001b[39m \u001b[33;03m        - rationale_str: str  # 예: \"[serotonin] '행복해' — 만족/평온 신호 (s≈0.80); [dopamine] '행복해' — 긍정·보상 연상 (s≈0.50)\"\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     prompt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIPT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m     raw = \u001b[38;5;28mself\u001b[39m._run_model(prompt)\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m log_raw \u001b[38;5;129;01mand\u001b[39;00m raw:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mLLM._build_prompt\u001b[39m\u001b[34m(self, IPT)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_build_prompt\u001b[39m(\u001b[38;5;28mself\u001b[39m, IPT: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     18\u001b[39m     fewshot = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(\n\u001b[32m     19\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mText: \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m<json>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson.dumps(ex,\u001b[38;5;250m \u001b[39mseparators=(\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m</json>\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m t, ex \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mEXAMPLES\u001b[49m\n\u001b[32m     21\u001b[39m     )\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.EMO_SYSTEM\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.CHEATSHEET\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfewshot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mText: \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mIPT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mJSON:\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m: 'LLM' object has no attribute 'EXAMPLES'"
     ]
    }
   ],
   "source": [
    "# LLM test\n",
    "_llm = LLM()\n",
    "ntl, why = _llm.IPT2NTL(\"행복해\", log_raw=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed98e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감정 저장소\n",
    "class emotion_storage():\n",
    "    def __init__(self):\n",
    "        self.NTL_bef = [0] # 이전 상태의 NTL\n",
    "        self.K = []\n",
    "    \n",
    "    def NTL2NTLandK(self, NTL):\n",
    "        K = -70 # 초기 전위\n",
    "        w = 0.1 # 이전 NTL 적용 가중치(10%)\n",
    "        if len(self.K) != 0:\n",
    "            for i, j in enumerate(self.K): # 시간 감쇠를 적용한 K 업데이트\n",
    "                K += i**(1/j)\n",
    "        NTL_bef_w = [i*w for i in self.NTL_bef]\n",
    "        NTL_final = [NTL[i] + NTL_bef_w[i] for i in range(4)]\n",
    "        return NTL_final, K\n",
    "    \n",
    "    def NTL_K_hist(self, NTL, K): # 마지막 모델에서 계산한 NTL, K를 현재 스텝의 최종 NTL, K로 기록\n",
    "        self.NTL_bef = NTL\n",
    "        self.K.append(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b42421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴런 정의\n",
    "K_remember = 100 # 기억 막전위\n",
    "\n",
    "class neuron():\n",
    "    def __init__(self, K_critical, code, type): # 노드 고유 번호(code)\n",
    "        self.K_critical = K_critical # 임계 막전위(활성화를 위한)\n",
    "        self.saved_IPT = [None]\n",
    "        self.code = code\n",
    "        self.connected_node = []\n",
    "        self.connected_node_code = []\n",
    "        self.w_bef = 0\n",
    "        self.w_curr = 0\n",
    "        self.K_out = []\n",
    "        self.NTL_out = []\n",
    "        self.IPT_curr = ''\n",
    "\n",
    "        self.type = type # types: exciting, inhibiting, modulating\n",
    "\n",
    "        self.K_final = 0\n",
    "        self.NTL_final = 0\n",
    "\n",
    "    def do_work(self, NTL, K):\n",
    "        #w 업데이트 시에는 self.w_curr을 업데이트 하기!\n",
    "        # 할일 code needed\n",
    "        return NTL, K\n",
    "    \n",
    "    def save(self, IPT):\n",
    "        self.saved_IPT.append(IPT)\n",
    "        self.IPT_curr = IPT\n",
    "\n",
    "    def make_new_connection(self, node): # 노드와 연결 함수\n",
    "        self.connected_node.append(node)\n",
    "        node.connected_node.append(self)\n",
    "\n",
    "        self.connected_node_code.append(node.code)\n",
    "        node.connected_node_code.append(self.code)\n",
    "        return node.code\n",
    "\n",
    "    def main(self, NTL, K, IPT, node):\n",
    "        if K > self.K_critical:\n",
    "            NTL_out, K_out = self.do_work(NTL, K)\n",
    "            self.NTL_out.append(NTL_out)\n",
    "        if node is not None:\n",
    "            self.K_out.append(K_out * getattr(node, \"w_bef\", 1.0))  # 기본 1.0\n",
    "        else:\n",
    "            self.K_out.append(K_out)\n",
    "\n",
    "        if K > K_remember: # IPT 기억 조건\n",
    "            self.save(IPT)\n",
    "            print('[LOG] IPT Saved')\n",
    "\n",
    "        if self.w_curr - self.w_bef > 0: # 가중치가 커지면 그만크 연결 노드 수 증가\n",
    "            for _ in range(int(self.w_curr - self.w_bef)):\n",
    "                available_node = list(set(node_codes + self.connected_node_code))\n",
    "                if not available_node:\n",
    "                    return  # 또는 continue\n",
    "                self.make_new_connection(nodes[available_node[0]-1])\n",
    "\n",
    "        K_final = sum(K_out) if self.K_out else 0\n",
    "        NTL_final = []\n",
    "        for i in range(4):\n",
    "            k=0\n",
    "            for j in NTL_out:\n",
    "                k += j[i]\n",
    "            NTL_final.append(k/len(NTL_out) if self.K_out else 0)\n",
    "\n",
    "        self.NTL_final = NTL_final\n",
    "        self.K_final = K_final\n",
    "        self.update_nodes()\n",
    "        return\n",
    "    \n",
    "    def update_nodes(self):\n",
    "        a_kept = self.saved_IPT.copy()\n",
    "        if self.IPT_curr in a_kept:\n",
    "            idx = a_kept.index(self.IPT_curr)\n",
    "            IPT_out = a_kept[:idx] + a_kept[idx+1:]\n",
    "        else:\n",
    "            IPT_out = [x for x in a_kept if x is not None]\n",
    "\n",
    "        if not IPT_out:\n",
    "            return  # 전파할 IPT가 없으면 종료\n",
    "\n",
    "        for i in self.connected_node:\n",
    "            i.main(self.NTL_final, self.K_final, IPT_out[-1], self)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d67dca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn 정의\n",
    "w_exciting = 0.33\n",
    "w_inhibiting = 0.33\n",
    "w_modulating = 0.34\n",
    "node_count = 100\n",
    "\n",
    "# 1) 비율 정리(혹시 합이 1이 아닐 수도 있으니 정규화)\n",
    "weights = [\n",
    "    ('exciting',  w_exciting),\n",
    "    ('inhibiting', w_inhibiting),\n",
    "    ('modulating', w_modulating),\n",
    "]\n",
    "total_w = sum(w for _, w in weights)\n",
    "weights = [(t, (w / total_w) if total_w else 0.0) for t, w in weights]\n",
    "\n",
    "# 2) 바닥 할당 + 나머지를 소수점 큰 순서대로 분배\n",
    "raw = [node_count * w for _, w in weights]\n",
    "base = [int(x) for x in raw]\n",
    "remainder = node_count - sum(base)\n",
    "\n",
    "# 소수 부분 큰 순서대로 remainder 만큼 1씩 추가\n",
    "frac_idx = sorted(range(len(raw)), key=lambda i: (raw[i] - base[i]), reverse=True)\n",
    "for k in range(remainder):\n",
    "    base[frac_idx[k]] += 1\n",
    "\n",
    "# 3) 노드 생성 (code 유니크하게 증가)\n",
    "nodes = []\n",
    "node_codes = []\n",
    "code = 0\n",
    "for (t, _), cnt in zip(weights, base):\n",
    "    for _ in range(cnt):\n",
    "        n = neuron(+30, code, t)   # 네 클래스명 그대로 사용\n",
    "        nodes.append(n)\n",
    "        node_codes.append(code)\n",
    "        code += 1\n",
    "\n",
    "node_count = len(nodes)  # 실제 생성된 수로 갱신\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd635b2",
   "metadata": {},
   "source": [
    "**FLOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b914c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class들 호출\n",
    "LLM = LLM()\n",
    "emotion_storage = emotion_storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2db5a0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 박스 구성\n",
    "data_box = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf2f064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT\n",
    "data_box['IPT'] = 'I hate you'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5119fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감정 저장소\n",
    "data_box['NTL'] = LLM.IPT2NTL(data_box['IPT'])\n",
    "data_box['NTL'], data_box['K'] = emotion_storage.NTL2NTLandK(data_box['NTL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3fa6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 뉴런 자극\n",
    "import random\n",
    "\n",
    "class dummy_node():\n",
    "    def __init__(self):\n",
    "        self.code = 0\n",
    "\n",
    "dummy_node = dummy_node()\n",
    "\n",
    "start_neuron = nodes[random.randrange(1, node_count+1)+1]\n",
    "start_neuron.main(data_box['NTL'], data_box['K'], data_box['IPT'], dummy_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196a8db2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
