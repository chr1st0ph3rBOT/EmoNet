{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dfa1678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\gptoss\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Fetching 40 files: 100%|██████████| 40/40 [00:00<?, ?it/s]\n",
      "Fetching 40 files: 100%|██████████| 40/40 [00:00<?, ?it/s]?it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:07<00:00,  2.65s/it]\n",
      "Device set to use cuda:0\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysisThe user says \"안녕! 테스트야.\" which is Korean: \"Hello! This is a test.\" They likely want a friendly response. The instruction: \"You are ChatGPT\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch, json, re, os\n",
    "\n",
    "os.environ[\"TORCH_COMPILE_DISABLE\"] = \"1\"   # PyTorch 2.8에서 안전\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "MODEL_ID = \"openai/gpt-oss-20b\"\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,   # gpt-oss 통합(MXFP4) 경로 활성\n",
    "    low_cpu_mem_usage=True,\n",
    ")\n",
    "\n",
    "gen = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tok,\n",
    ")\n",
    "\n",
    "# 간단 구동 체크\n",
    "resp = gen([{\"role\": \"user\", \"content\": \"안녕! 테스트야.\"}], max_new_tokens=40, do_sample=False)\n",
    "print(resp[0][\"generated_text\"][-1][\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0153f2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have loaded an FP4 model on CPU and have a CUDA device available, make sure to set your model on a GPU device in order to run your model. To remove this warning, pass device_map = 'cuda'. \n",
      "Fetching 40 files: 100%|██████████| 40/40 [00:00<?, ?it/s]\n",
      "Fetching 40 files: 100%|██████████| 40/40 [00:00<?, ?it/s]?it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.10s/it]\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysisThe user says \"안녕! 테스트야.\" which is Korean: \"Hello! This is a test.\" They likely want a friendly response. The instruction: \"You are ChatGPT\n"
     ]
    }
   ],
   "source": [
    "import os, torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# 안전: 토치 컴파일 끄기\n",
    "os.environ[\"TORCH_COMPILE_DISABLE\"] = \"1\"\n",
    "\n",
    "MODEL_ID = \"openai/gpt-oss-20b\"\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=None,           # <- auto 금지\n",
    "    low_cpu_mem_usage=False,   # <- 지연 로드 금지 (meta 방지)\n",
    ")\n",
    "model.to(\"cuda\")               # <- 즉시 materialize\n",
    "model.eval()\n",
    "\n",
    "gen = pipeline(\"text-generation\", model=model, tokenizer=tok)\n",
    "\n",
    "# 짧게 구동 체크\n",
    "out = gen([{\"role\": \"user\", \"content\": \"안녕! 테스트야.\"}],\n",
    "          max_new_tokens=40, do_sample=False)[0][\"generated_text\"]\n",
    "print(out[-1][\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb390b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion vector [DA,5-HT,NE,MLT] = [0.2, 0.3, 0.4, 0.6]\n",
      "raw = {'dopamine': 0.2, 'serotonin': 0.3, 'norepinephrine': 0.4, 'melatonin': 0.6}\n"
     ]
    }
   ],
   "source": [
    "import json, re\n",
    "\n",
    "SYSTEM = (\n",
    "    \"You are EmotionScore. Respond with JSON ONLY. \"\n",
    "    \"Return exactly these four keys as floats in [0,1]: \"\n",
    "    \"dopamine, serotonin, norepinephrine, melatonin. \"\n",
    "    \"Do not write any other text, no explanation.\"\n",
    ")\n",
    "\n",
    "def emotion_vector(text: str):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM},\n",
    "        {\"role\": \"user\", \"content\": f\"Text: {text}\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"{\"}  # JSON 강제 시작\n",
    "    ]\n",
    "    out = gen(messages, max_new_tokens=60, do_sample=False,\n",
    "              return_full_text=False)[0][\"generated_text\"]\n",
    "    content = \"{\" + out\n",
    "\n",
    "    m = re.search(r\"\\{.*\\}\", content, re.S)\n",
    "    if not m:\n",
    "        raise RuntimeError(f\"JSON not found in: {content[:200]}\")\n",
    "    data = json.loads(m.group())\n",
    "\n",
    "    def c(x): \n",
    "        try: return max(0.0, min(1.0, float(x)))\n",
    "        except: return 0.0\n",
    "    vec = [c(data.get(k)) for k in (\"dopamine\",\"serotonin\",\"norepinephrine\",\"melatonin\")]\n",
    "    return vec, data\n",
    "\n",
    "# 테스트\n",
    "demo = \"우울하다\"\n",
    "vec, raw = emotion_vector(demo)\n",
    "print(\"emotion vector [DA,5-HT,NE,MLT] =\", vec)\n",
    "print(\"raw =\", raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66b4fd23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.92, 0.88, 0.75, 0.3],\n",
       " {'dopamine': 0.92,\n",
       "  'serotonin': 0.88,\n",
       "  'norepinephrine': 0.75,\n",
       "  'melatonin': 0.3})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_scores(text: str):\n",
    "    vec, raw = emotion_vector(text)  # 여기서 vec=[DA,HT,NE,MLT], raw는 JSON\n",
    "    return vec, raw\n",
    "\n",
    "fetch_scores(\"오늘 너무 행복해!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8967f62",
   "metadata": {},
   "source": [
    "**흥분성 뉴런**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc395162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ModNeuronCfg:\n",
    "    v_leak: float = 0.90            # 기억이 없어지는 정도(누설 전위)\n",
    "    g0: float = 1.0                 # 입력 신호의 기본 증폭률\n",
    "    a_ne: float = 0.8               # NE의 증폭률\n",
    "    a_mlt: float = 1.0              # MLT의 억제률\n",
    "    theta0: float = 1.0             # 초기 임계 값\n",
    "    k_theta: float = 0.6            # 세로토닌의 임계값 증가율\n",
    "    theta_homeo: float = 0.2        # 스파이크가 발생하면 임계를 조금 낮추는 값(발화 후 다시 발화할 수 있게 임계 살짝 내려감)\n",
    "    theta_min: float = 0.2          # 임계값 최소\n",
    "    theta_max: float = 2.5          # 임계값 최대\n",
    "    W0: float = 0.5                 # 초기 가중치\n",
    "    eta: float = 0.25               # 학습률\n",
    "    rho: float = 0.9                # 적격도 감쇠율\n",
    "    # 적격도: 시냅스가 최근에 활성된 사실을 잠시 기억해 두었다가, 나중에 보상 신호(도파민 등)가 도착했을 때 그 연결을 강화하거나 약화할 수 있게 해 주는 일시적 흔적\n",
    "    W_min: float = 0.0              # 가중치 최소\n",
    "    W_max: float = 3.0              # 가중치 최대\n",
    "    v_min: float = -1.0             # 전위 최소\n",
    "    v_max: float = 5.0              # 전위 최대\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dcae140",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniNeuron:\n",
    "    def __init__(self, fetch_scores, cfg: ModNeuronCfg = ModNeuronCfg()):\n",
    "        self.cfg = cfg\n",
    "        self.fetch_scores = fetch_scores\n",
    "        self.v = 0.0 # 뉴런의 막 전위\n",
    "\n",
    "    def step(self, text: str, x_t: float = 1.0):\n",
    "        (DA, HT, NE, MLT), raw = self.fetch_scores(text)  # vec = [DA, HT, NE, MLT]\n",
    "        g = self.cfg.g0 * (1.0 + self.cfg.a_ne * NE - self.cfg.a_mlt * MLT)  # gain(g): 입력 신호를 얼마나 크게 증폭/감쇠할지 결정하는 계수\n",
    "        g = max(0.0, g)  # 음수 방지\n",
    "        I = g * x_t # 받은 입력 자극\n",
    "        self.v = self.cfg.v_leak * self.v + I\n",
    "        return {\"mods\":{\"DA\":DA,\"HT\":HT,\"NE\":NE,\"MLT\":MLT},\n",
    "                \"gain\": g, \"I\": I, \"v\": self.v, \"raw\": raw}\n",
    "    \n",
    "mn = MiniNeuron(fetch_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8656c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NE↑ : {'gain': 1.504, 'I': 1.504, 'v': 1.504}\n"
     ]
    }
   ],
   "source": [
    "o1 = mn.step(\"긴장감이 올라 집중이 잘 된다. 빠르게 대응한다.\")\n",
    "print(\"NE↑ :\", {k:round(v,3) if isinstance(v,float) else v for k,v in o1.items() if k in (\"gain\",\"I\",\"v\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b1aac87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLT↑: {'gain': 0.28, 'I': 0.28, 'v': 1.634}\n"
     ]
    }
   ],
   "source": [
    "o2 = mn.step(\"피곤하고 졸리다. 의욕이 떨어진다.\")  # MLT↑ 기대\n",
    "print(\"MLT↑:\", {k:round(v,3) if isinstance(v,float) else v for k,v in o2.items() if k in (\"gain\",\"I\",\"v\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "403d5fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mini neuron에서 업그레이드 버전\n",
    "class SpikeNeuron:\n",
    "    def __init__(self, fetch_scores, cfg: ModNeuronCfg = ModNeuronCfg()):\n",
    "        self.cfg = cfg\n",
    "        self.fetch_scores = fetch_scores\n",
    "        self.v = 0.0\n",
    "        self.theta = cfg.theta0\n",
    "        self.W = cfg.W0\n",
    "\n",
    "    def step(self, text: str, x_t: float = 1.0):\n",
    "        (DA, HT, NE, MLT), raw = self.fetch_scores(text)\n",
    "\n",
    "        dW = 0.0  # 가중치 변화량 초기화\n",
    "\n",
    "        # 입력 게인 계산\n",
    "        g = self.cfg.g0 * (1.0 + self.cfg.a_ne * NE - self.cfg.a_mlt * MLT)\n",
    "        g = max(0.0, g)\n",
    "\n",
    "        # 막전위 계산\n",
    "        I = g * x_t\n",
    "        self.v = self.cfg.v_leak * self.v + I\n",
    "\n",
    "        # 스파이크 여부 결정\n",
    "        spike = 1 if self.v >= self.theta else 0\n",
    "        if spike:\n",
    "            self.v = 0.0  # 발화 후 막전위 리셋\n",
    "            # 도파민이 클 수록 가중치 증가\n",
    "            dW = self.cfg.eta * DA\n",
    "            self.W = min(self.cfg.W_max, max(self.cfg.W_min, self.W + dW))\n",
    "\n",
    "        return {\n",
    "            \"mods\": {\"NE\": NE, \"MLT\": MLT},\n",
    "            \"gain\": g, \"I\": I, \"v\": self.v,\n",
    "            \"theta\": self.theta, \"spike\": spike,\n",
    "            \"W\": self.W, \"dW\": dW\n",
    "        }\n",
    "sn = SpikeNeuron(fetch_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79ca30bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: v=0.301, theta=1.000, spike=0\n",
      "step 1: v=0.572, theta=1.000, spike=0\n",
      "step 2: v=0.815, theta=1.000, spike=0\n",
      "step 3: v=0.000, theta=1.000, spike=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4: v=0.301, theta=1.000, spike=0\n",
      "step 5: v=0.572, theta=1.000, spike=0\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    out = sn.step(\"긴장감이 올라 집중이 잘 된다. 빠르게 대응한다.\", x_t=0.2)  # NE↑ 문장 x_t: 입력 세기\n",
    "    print(f\"step {i}: v={out['v']:.3f}, theta={out['theta']:.3f}, spike={out['spike']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75557fb",
   "metadata": {},
   "source": [
    "**억제성 뉴런**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef8078d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "@dataclass\n",
    "class InhibNeuronCfg:\n",
    "    v_leak: float = 0.9\n",
    "    theta0: float = 1.0\n",
    "    W0: float = 0.5\n",
    "    W_min: float = 0.0\n",
    "    W_max: float = 3.0\n",
    "    eta: float = 0.2  # 학습률 기본치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca6419c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InhibitoryNeuron:\n",
    "    \"\"\"\n",
    "    억제성 뉴런 (GABA):\n",
    "      - 입력 적분 → 발화(spike) → downstream 뉴런 억제 신호\n",
    "      - 세로토닌 HT: 억제성 강화/약화 비율에 큰 영향\n",
    "      - 도파민 DA: 보상 학습 비율에 영향\n",
    "    \"\"\"\n",
    "    def __init__(self, fetch_scores, cfg: InhibNeuronCfg = InhibNeuronCfg()):\n",
    "        self.cfg = cfg\n",
    "        self.fetch_scores = fetch_scores\n",
    "        self.v = 0.0\n",
    "        self.theta = cfg.theta0\n",
    "        self.W = cfg.W0\n",
    "\n",
    "    def step(self, text: str, x_t: float = 1.0):\n",
    "        (DA, HT, NE, MLT), raw = self.fetch_scores(text)\n",
    "\n",
    "        dW = 0.0  # 가중치 변화량 초기화\n",
    "\n",
    "        # 막전위 계산\n",
    "        I = self.W * x_t\n",
    "        self.v = self.cfg.v_leak * self.v + I\n",
    "\n",
    "        # 스파이크 여부\n",
    "        spike = 1 if self.v >= self.theta else 0\n",
    "        if spike:\n",
    "            self.v = 0.0  # 발화 후 리셋\n",
    "\n",
    "        # 학습 규칙 (세로토닌, 도파민에 따른 가중치 업데이트)\n",
    "        if spike:\n",
    "            # 강화 비율\n",
    "            dW_up = (0.9 * HT) + (0.7 * DA)\n",
    "            # 약화 비율\n",
    "            dW_down = (0.1 * HT) + (0.3 * DA)\n",
    "\n",
    "            # 변화량 = eta * (강화 - 약화)\n",
    "            dW = self.cfg.eta * (dW_up - dW_down)\n",
    "\n",
    "            # 가중치 업데이트\n",
    "            self.W = min(self.cfg.W_max, max(self.cfg.W_min, self.W + dW))\n",
    "\n",
    "        return {\n",
    "            \"mods\": {\"DA\": DA, \"HT\": HT, \"NE\": NE, \"MLT\": MLT},\n",
    "            \"I\": I, \"v\": self.v, \"theta\": self.theta, \"spike\": spike,\n",
    "            \"W\": self.W, \"dW\": dW, \"raw\": raw\n",
    "        }\n",
    "    \n",
    "inh = InhibitoryNeuron(fetch_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "656a2053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5 0 0.5\n",
      "1 0.95 0 0.5\n",
      "2 0.0 1 0.652\n",
      "3 0.652 0 0.652\n",
      "4 0.0 1 0.804\n"
     ]
    }
   ],
   "source": [
    "# 세로토닌 강화 케이스\n",
    "for i in range(5):\n",
    "    out = inh.step(\"마음이 차분하고 안정적이다. 욕구가 억제된다.\")\n",
    "    print(i, out[\"v\"], out[\"spike\"], out[\"W\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e0662a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 v=0.161 spike=0 W=0.804 dW=0.0000\n",
      "1 v=0.306 spike=0 W=0.804 dW=0.0000\n",
      "2 v=0.436 spike=0 W=0.804 dW=0.0000\n",
      "3 v=0.553 spike=0 W=0.804 dW=0.0000\n",
      "4 v=0.658 spike=0 W=0.804 dW=0.0000\n"
     ]
    }
   ],
   "source": [
    "text = \"드디어 대회에 합격했다! 팀원들과 소리 지르며 기뻐했다.\"\n",
    "\n",
    "for i in range(5):\n",
    "    out = inh.step(text, x_t=0.2)\n",
    "    print(f\"{i} v={out['v']:.3f} spike={out['spike']} W={out['W']:.3f} dW={out['dW']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56216d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ModulatoryNeuronCfg:\n",
    "    eta_base: float = 0.2      # 기본 학습률\n",
    "    theta_base: float = 1.0    # 기본 임계값\n",
    "    gain_base: float = 1.0     # 기본 게인\n",
    "\n",
    "class ModulatoryNeuron:\n",
    "    \"\"\"\n",
    "    조절성 뉴런:\n",
    "      - 직접 발화하지 않고, 다른 뉴런의 파라미터(θ, η, W 등)를 조정\n",
    "    \"\"\"\n",
    "    def __init__(self, fetch_scores, cfg: ModulatoryNeuronCfg = ModulatoryNeuronCfg()):\n",
    "        self.cfg = cfg\n",
    "        self.fetch_scores = fetch_scores\n",
    "\n",
    "    def modulate(self, text: str, neuron_params: dict):\n",
    "        (DA, HT, NE, MLT), raw = self.fetch_scores(text)\n",
    "\n",
    "        # 조절\n",
    "        theta = neuron_params.get(\"theta\", self.cfg.theta_base)\n",
    "        eta   = neuron_params.get(\"eta\", self.cfg.eta_base)\n",
    "        gain  = neuron_params.get(\"gain\", self.cfg.gain_base)\n",
    "\n",
    "        # 도파민: 학습률 증가 (동기/보상)\n",
    "        eta *= (1.0 + 0.5 * DA)\n",
    "\n",
    "        # 세로토닌: 임계값 증가 (안정화)\n",
    "        theta *= (1.0 + 0.5 * HT)\n",
    "\n",
    "        # 노르아드레날린: 전체 게인 증가(각성)\n",
    "        gain *= (1.0 + 0.8 * NE)\n",
    "\n",
    "        # 아세틸콜린: 발화율 높은 상황에서 학습률 추가 조정 (여기선 단순히 +20%)\n",
    "        if neuron_params.get(\"firing_rate\", 0) > 0.5:\n",
    "            eta *= 1.2\n",
    "\n",
    "        return {\"theta\": theta, \"eta\": eta, \"gain\": gain,\n",
    "                \"mods\": {\"DA\": DA, \"HT\": HT, \"NE\": NE, \"MLT\": MLT}, \"raw\": raw}\n",
    "mod = ModulatoryNeuron(fetch_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d5c7fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'theta': 1.275, 'eta': 0.342, 'gain': 1.6400000000000001, 'mods': {'DA': 0.85, 'HT': 0.55, 'NE': 0.8, 'MLT': 0.1}, 'raw': {'dopamine': 0.85, 'serotonin': 0.55, 'norepinephrine': 0.8, 'melatonin': 0.1}}\n"
     ]
    }
   ],
   "source": [
    "# 어떤 뉴런이 현재 가진 파라미터 예시\n",
    "neuron_params = {\"theta\": 1.0, \"eta\": 0.2, \"gain\": 1.0, \"firing_rate\": 0.6}\n",
    "\n",
    "out = mod.modulate(\"긴장되고 흥분되며 보상이 기대된다.\", neuron_params)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cdd965f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "조절성 출력: {'theta': 1.425, 'eta': 0.438, 'gain': 1.624, 'mods': {'DA': 0.92, 'HT': 0.85, 'NE': 0.78, 'MLT': 0.12}, 'raw': {'dopamine': 0.92, 'serotonin': 0.85, 'norepinephrine': 0.78, 'melatonin': 0.12}}\n",
      "step 0: v=1.247, theta=1.425, gain=2.442, spike=0, dW=0.000\n",
      "step 1: v=0.000, theta=1.425, gain=2.442, spike=1, dW=0.403\n",
      "step 2: v=0.733, theta=1.425, gain=2.442, spike=0, dW=0.000\n",
      "step 3: v=1.392, theta=1.425, gain=2.442, spike=0, dW=0.000\n",
      "step 4: v=0.000, theta=1.425, gain=2.442, spike=1, dW=0.403\n",
      "step 5: v=0.733, theta=1.425, gain=2.442, spike=0, dW=0.000\n",
      "step 6: v=1.392, theta=1.425, gain=2.442, spike=0, dW=0.000\n",
      "step 7: v=0.000, theta=1.425, gain=2.442, spike=1, dW=0.403\n"
     ]
    }
   ],
   "source": [
    "# 테스트 문장 (강한 보상, 각성)\n",
    "text = \"드디어 대회에 합격했다! 팀원들과 소리 지르며 기뻐했다.\"\n",
    "\n",
    "# 조절성 뉴런으로 파라미터 조정\n",
    "mod_out = mod.modulate(\n",
    "    text,\n",
    "    {\"theta\": sn.theta, \"eta\": sn.cfg.eta, \"gain\": sn.cfg.g0, \"firing_rate\": 0.6}\n",
    ")\n",
    "print(\"조절성 출력:\", mod_out)\n",
    "\n",
    "# SpikeNeuron에 반영\n",
    "sn.theta = mod_out[\"theta\"]        # 임계값 조정\n",
    "sn.cfg.eta = mod_out[\"eta\"]        # 학습률 업데이트\n",
    "sn.cfg.g0 = mod_out[\"gain\"]        # 게인 업데이트\n",
    "\n",
    "# 여러 step 실행\n",
    "for i in range(8):\n",
    "    out = sn.step(text, x_t=0.3)\n",
    "    print(f\"step {i}: v={out['v']:.3f}, theta={out['theta']:.3f}, \"\n",
    "          f\"gain={out['gain']:.3f}, spike={out['spike']}, dW={out['dW']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d3d5580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Network:\n",
    "    def __init__(self, fetch_scores, n_exc=3, n_inh=2, n_mod=1):\n",
    "        self.exc_neurons = [SpikeNeuron(fetch_scores) for _ in range(n_exc)]\n",
    "        self.inh_neurons = [InhibitoryNeuron(fetch_scores) for _ in range(n_inh)]\n",
    "        self.mod_neurons = [ModulatoryNeuron(fetch_scores) for _ in range(n_mod)]\n",
    "\n",
    "        # 뉴런 전체 리스트 (인덱스로 관리)\n",
    "        self.neurons = self.exc_neurons + self.inh_neurons + self.mod_neurons\n",
    "        self.n_total = len(self.neurons)\n",
    "\n",
    "        # 연결 가중치 행렬 초기화\n",
    "        self.connections = np.random.uniform(0.1, 1.0, size=(self.n_total, self.n_total))\n",
    "\n",
    "        # 억제성 뉴런 인덱스\n",
    "        self.exc_idx = range(0, n_exc)\n",
    "        self.inh_idx = range(n_exc, n_exc + n_inh)\n",
    "        self.mod_idx = range(n_exc + n_inh, self.n_total)\n",
    "\n",
    "        # 자기 연결 제거\n",
    "        np.fill_diagonal(self.connections, 0.0)\n",
    "\n",
    "        # 억제 뉴런 → 모든 출력은 음수로\n",
    "        for i in self.inh_idx:\n",
    "            self.connections[i, :] = -np.abs(self.connections[i, :])\n",
    "\n",
    "        # 행 정규화 (폭주 방지)\n",
    "        row_norm = np.maximum(np.sum(np.abs(self.connections), axis=1, keepdims=True), 1e-6)\n",
    "        self.connections = self.connections / row_norm * 0.5  # 각 행 합 ≈ 0.5\n",
    "\n",
    "        # 재귀 입력 혼합 비율\n",
    "        self.alpha = 0.3  \n",
    "\n",
    "    def step(self, text: str, inputs=None):\n",
    "        if inputs is None:\n",
    "            # 외부 기본 입력 (약한 값)\n",
    "            inputs = np.array([0.1] * self.n_total)\n",
    "        else:\n",
    "            inputs = np.array(inputs)\n",
    "\n",
    "        spikes = [0] * self.n_total\n",
    "        outputs = []\n",
    "\n",
    "        # 각 뉴런 업데이트\n",
    "        for i, neuron in enumerate(self.neurons):\n",
    "            if isinstance(neuron, ModulatoryNeuron):\n",
    "                # 조절성 뉴런은 파라미터 조정\n",
    "                mod_out = neuron.modulate(text, {\n",
    "                    \"theta\": self.neurons[0].theta,\n",
    "                    \"eta\": self.neurons[0].cfg.eta,\n",
    "                    \"gain\": self.neurons[0].cfg.g0,\n",
    "                    \"firing_rate\": 0.5,\n",
    "                })\n",
    "                # 흥분성 뉴런 파라미터에 적용\n",
    "                for exc in self.exc_neurons:\n",
    "                    exc.theta = mod_out[\"theta\"]\n",
    "                    exc.cfg.eta = mod_out[\"eta\"]\n",
    "                    exc.cfg.g0 = mod_out[\"gain\"]\n",
    "                out = mod_out\n",
    "                spike = 0\n",
    "            else:\n",
    "                out = neuron.step(text, x_t=inputs[i])\n",
    "                spike = out[\"spike\"]\n",
    "\n",
    "            spikes[i] = spike\n",
    "            outputs.append(out)\n",
    "\n",
    "        spikes = np.array(spikes)\n",
    "\n",
    "        # 스파이크 결과를 다음 step 입력에 반영\n",
    "        inputs_next = np.dot(spikes, self.connections)\n",
    "\n",
    "        # 포화/클리핑 적용\n",
    "        inputs_next = np.clip(inputs_next, 0, 1)\n",
    "\n",
    "        # 외부 입력과 혼합 (alpha 비율)\n",
    "        inputs_mixed = self.alpha * inputs_next + (1 - self.alpha) * inputs\n",
    "\n",
    "        return {\n",
    "            \"spikes\": spikes.tolist(),\n",
    "            \"outputs\": outputs,\n",
    "            \"inputs_next\": inputs_mixed.tolist()\n",
    "        }\n",
    "net = Network(fetch_scores, n_exc=3, n_inh=2, n_mod=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "526f06b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: spikes=[0, 0, 0, 0, 0, 0], inputs_next=[0.06999999999999999, 0.06999999999999999, 0.06999999999999999, 0.06999999999999999, 0.06999999999999999, 0.06999999999999999]\n",
      "Step 1: spikes=[0, 0, 0, 0, 0, 0], inputs_next=[0.06999999999999999, 0.06999999999999999, 0.06999999999999999, 0.06999999999999999, 0.06999999999999999, 0.06999999999999999]\n",
      "Step 2: spikes=[0, 0, 0, 0, 0, 0], inputs_next=[0.06999999999999999, 0.06999999999999999, 0.06999999999999999, 0.06999999999999999, 0.06999999999999999, 0.06999999999999999]\n",
      "Step 3: spikes=[0, 0, 0, 0, 0, 0], inputs_next=[0.06999999999999999, 0.06999999999999999, 0.06999999999999999, 0.06999999999999999, 0.06999999999999999, 0.06999999999999999]\n",
      "Step 4: spikes=[0, 0, 0, 0, 0, 0], inputs_next=[0.06999999999999999, 0.06999999999999999, 0.06999999999999999, 0.06999999999999999, 0.06999999999999999, 0.06999999999999999]\n"
     ]
    }
   ],
   "source": [
    "text = \"드디어 대회에 합격했다! 팀원들과 소리 지르며 기뻐했다.\"\n",
    "for t in range(5):\n",
    "    result = net.step(text)\n",
    "    print(f\"Step {t}: spikes={result['spikes']}, inputs_next={result['inputs_next']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptoss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
